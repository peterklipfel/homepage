A Case for Strong Artificial Intelligence through the use of Genetic Algorithms
===

Genetic Programs
---------

Genetic programming is a programming technique that encodes information about a program or algorithm in a “genome”.  It is used to solve problems in which the number of possible states of a system (state space) is very large.  Many different genomes are produced and each permutation of the code is evaluated against a fitness function to determine if the encoded information should be passed on to the next generation of programs.  There has already been a great deal of research on the subject of using genetic algorithms to optimize certain engineering problems like designing circuits (Coello et al., 2002).  In this case, rather than optimizing logic for circuits, genetic algorithms can be used to optimize logic for a program.

The information that is encoded in the genome of the genetic program is normally structured as a parse tree, but for simplicity, the following example will use just a number in the genome.  This number can be thought of as the only “gene” in the genome.  In this uncomplicated case, the purpose of the genome is to keep track of a numerical parameter of the program.  A simple example is a counter.  Imagine creating a program that counts to the highest number possible using a loop that iteratively adds 1 to a running total that begins at 0.  The loop will be performed x times so the genome can consist solely of x.  The first step is to create a population of programs.  In this case it might be useful to make a population whose x values are between 30,000 and -30,000.  Because the program is trying to find a genome that produces the highest number, it must compare all of the genomes in the population against each other and take the top performing genomes.  In this case, it might be useful to take the top 25%.  In order to decide which genomes perform the best, they are run through what is known as a fitness function.

In this case, the fitness function tests whether a genome in the population produces a number that is in the top 25% of numbers produced by all the programs.  These genomes are then combined to produce children with a similar genome.  A simple way to create children would be to average x from the parents.  To keep the size of the population the same, 8 child genomes must be produced per pair of parent genomes .  In order to maintain diversity in the population, a mutation is applied to each of the children.  A reasonable method for doing so would be to add or subtract a random number to x, where larger numbers are more unlikely.  Because the amount of memory in a computer is finite, this evolution would converge on the largest number that could be represented by the computer.  Depending on the implementation, this number might be the largest integer.  In the case of an integer, after a certain amount of time, the entire population would converge to 2,147,483,647 .  If the computer tries to store any number larger than 2,147,483,647, the number that it actually stores will be extremely small .  Genetic programs will converge on the optimal solution of the fitness function.  Because the fitness function of the counter was to produce the largest number, eventually the population will approach 2,147,483,647. Devising a fitness function for is much more difficult when dealing with strong AI.

In practice, the genome is more complex and is stored as a parse tree.  This means that rather than storing a parameter of the program in the genome, the genome itself is the program.  An in depth review of parse trees is beyond the scope of this paper, but suffice it to say that they are much more complex and powerful than storing parameters of programs.  In the example of the counter, the genome contained a parameter of the program instead of the program itself.  Parse trees allow direct manipulation of the structure of the program; therefore, it is possible to change whether some variable is equal to the summation of two numbers or the multiplication of two numbers.  In more complex cases, it is possible to change the logic that governs how the program responds to its surroundings, and the information it stores.

In order to facilitate learning in a program, the program must be allowed it to modify its own code so as to cope with different situations.  This is the most delicate part of developing an artificial intelligence because any slight infraction in the parse tree renders a program unusable.  If a computer can be taught to rewire itself to cope with new situations, then possibilities open for it to use tools, to learn language, and to even surpass human capability.



Strong AI
---------

The definition of strong artificial intelligence used for the remainder of this paper is given by Ray Kurzweil as “the intelligence of a machine that can successfully perform any intellectual task that a human being can” (Kurzweil, 2008).  This is slightly different than the definition that Alan Turing proposed in 1950.  Turing’s definition of intelligence was given by an intelligence test based on whether or not a computer could fool a human into thinking that the computer was actually human (Turing, 1950). Kurzweil’s definition extends beyond that, saying that the computer would also be able perform any task that humans can.

This assertion has been met with contentions that a computer will not be able to match human intelligence because it does not understand.  In this case, John Searle’s Chinese room argument is one of the canonical counterarguments to the idea of artificial intelligence (Searle, 1980).  Searle’s conjecture states that a machine cannot understand what it is doing because it is just executing a program.  This argument is framed as an example of a man in a room who must respond to Chinese.  He is only given a set of rules about which symbols must follow one another, and is passed slips of paper with Chinese symbols.  When he gets a slip, he reads the rules and hands an appropriate response back.  This man has no idea what the symbols mean, but to someone on the other side of the wall, he seems to.

This idea extends to computers.  They do not understand what they are doing.  They are only processing inputs in a specified way.  However, is this not what the brain is doing?  One response to Searle’s conjecture is to ask the following.  At what point would the man understand?  If the man is given pictures that are associated with symbols, would it be reasonable to say that he understands then?  What if sound clips of people saying the words are added?  Why stop there?  Videos that are associated with strings of words could be added.  The man could be given graphs of data about when to use certain words as a function of locality.  Surely, if the man knows what the language sounds like, learns to speak it, knows what words are associated with particular images, and knows how the words are meant to be combined it is reasonable to think that he understands the language.  If now the man is replaced by a computer, and if the computer has rules that dictate how all of these things are connected and it can respond in a seemingly intelligent manner, would that not be understanding?  What if the computer wrote these rules all on its own?

That is the strong AI that inspires researchers around the world.  With computers becoming ever more powerful and advances in programming techniques, it is becoming increasingly feasible to make computers program themselves.  What sorts or rules will be encoded and how can they be encoded?



The Architecture of Intelligence
---------

Medical researchers have managed to attribute certain activities to specific parts of the brain.  Interestingly, many of these functions of the brain are the subject of analogous fields of research in artificial intelligence.  In the codebase of the strong AI being developed in this paper, separate functional aspects of the brain should also be separated.  That is, there must be a specific system dedicated to certain functions like visual processing, memory, non-visual stimuli, and so on.  These, of course, could then be broken down further into smaller components.  These smaller components are the parts of the program that would be comprised of genomes that each represent the solution to a particular fitness function.  

In order to run the programs and decide which ones are the best, there must be another program that is parsing and executing the genetic programs.  This part must also be a part of the intelligence, but should not get in the way of the brain’s ability to rewire itself.  This means that its functionality should be very limited.  After all, the intelligence should be able to modify fitness functions as well.  It is interesting to consider which part of the brain this should represent.  In theory, this part of the program could also be modified dynamically if there were a reasonable assessment for testing the entire brain.  One solution is a trial similar to the Turing test.  The trial would require an intelligence to learn new concepts in an environment in which humans learn as well as require the intelligence to create a tool.  

In order to store memories, the program needs to keep a log of the inputs that it receives and the corresponding actions performed.  With the advent of ever more advanced databases, this task appears increasingly plausible.  The memories can be represented as a network of interconnected causalities that can be traversed to devise fitness functions and rethink past experiences.  In order to deal with the amount of data that this would produce, significance could be ascribed to different events and events with little significance can be overwritten when space runs out.  

By giving different memories certain ratings of significance, it becomes possible to write logic around the significance of memories.  For example, it would be possible to give an artificial intelligence the ability to be bored.  This would likely be implemented as a test of convergence of a particular activity.  If the intelligence asks someone if they enjoy pain and receives “no” as a response over and over, the answer to this question seems to converge.  Convergence and routine are boring.  This could be stored with a low value of “interest” significance, but might be stored with a high value of “anthropomorphic preferences” significance if such a significance has been devised by the intelligence.  There might also be a way to assign significance to various functions and activities.  That is, a higher weight could be applied to the “death” significance than to the “interest” significance.

The next difficulty that must be overcome to build strong AI is to give a computer the ability to come up with something entirely new.  How can a computer figure out how to implement new weightings in its codebase?



Meta-Thinking and Abstraction
---------

Unsupervised learning algorithms make it possible for artificial intelligence to find and track patterns in data.  In this case, data gathered from inputs could be fed to algorithms which cluster around data.  When significant clusters are found, a new weighting is added to the network of memories.  These weightings would then be added to the genome of the genetic algorithms.  In other words, the computer would now have a new weighting to evaluate inside of the code that makes it run.

Not only would the program be able to change the weighting of significance factors (found in the memory network) in its genome, but it would be able to assess entirely new sections to the genome.  The ability to add to the genome gives us the power to add entirely new components.  For example, suppose that the vision system keeps a 5 second buffer and every time it hits a threshold for action, the 5 second buffer is stored to memory, the action is taken, and then another 5 seconds of video is stored.  This data can then be analyzed with clustering algorithms  to find things that might be of importance.  

Suppose that in this particular case, there exists an automaton that is capable of moving its vision system (likely a camera).  This automaton has gyros and accelerometers in it so that it also knows where up and down are as well as a humidity sensor.  This automaton has been programmed to move its vision system at least once every 5 minutes, and it looks up from atop a roof.  For the lifespan of this automaton so far, it has only seen blue sky, and received relatively low input from the humidity sensor.  The components in the vision system that deal with color analysis interface with the other parts of the brain, and are quite simple at this point.  The robot knows that there is high clustering for the color black when it looks down, and high clustering for the color blue when it looks up .  As such, the logic in the color analysis component only contains information relevant to blue, black, up, and down.  One day, the sky is cloudy, so the vision system reports something that is not blue when the automaton looks up.  Now the automaton has 5 seconds of video that its clustering algorithm can work with.  This returns a high clustering in a new part of the state space that represents color.  The clustering is above a certain threshold, so the intelligence can now add a weighting to all of the nodes in its memory network that represents clustering around this information sample.  Also, the intelligence can reflect a new parameter into its components in the next generation of programs that run the color analysis component.  The intelligence has now learned the existence of a new color.  It might not be labeled as “grey” in the computer, but it can respond and deal with the new color.  This becomes even more powerful when there are actions that can be taken by the automaton.

In order to be able to deal with a dynamic world, the fitness functions that evaluate whether a particular component is optimal must be dynamic.  This is an extremely difficult problem, but there are theories that support an ability to do so.  Hendrick Richter and Shengxiang Yang describe a method to deal with devising fitness functions dynamically (Richter et al., 2008)  Their method adds an abstraction on top of the storage of the parse trees so the parse trees may be modified when the environment changes.  Of course, the automaton must be given some sort of solid basis on which to test all of the outcomes of its experiences.  This basis would consist of rules like “Don’t die”, “Find a Mate”, and other rules that could be attributable to instinct in humans.  As an added precaution, the rule “Don’t kill humans” could be added to the set of unchangeable rules.



Intelligence
---------

Suppose further that this automaton had wheels as well as its moveable visual system and it is given a goal to find maximal clustering to a certain threshold, and then find clustering that it has never seen before.  This automaton could display some remarkable traits without genetic algorithms governing a changing brain.  A progression of events might happen to be something like the following: the robot looks up and finds high clustering for the color of the sky. The robot looks down and finds high clustering for the color of the rooftop.  Over time, the clustering threshold is reached, and the robot needs to find something new.  So rather than moving the vision system, it now moves its wheels and finds that clustering for the rooftop has changed.  This automaton might appear to be very curious.  One might also be able to classify it as an explorer.

This automaton is displaying intelligent behavior even without genetic algorithms governing the functionality.  If genetic algorithms are now introduced, nuanced and varied behavior can be produced.  Suppose that there were many of these automata.  They would all evolve in different ways.  A simple case might be two automata that develop a preference for certain color clusters.  These could be manifested as different weightings in clustering significance.  In a more interesting case, imagine that the fitness function of the color analysis system has a greater-than sign changed to a less-than sign.  Now the fitness function prefers less clustering and will avoid staring at things that have a consistent color.  It will instead prefer to look at the horizon, where there are multiple colors that meet.

Because this sort of nuanced behavior can occur in any of the components for which genetic algorithms are used, there is the possibility for extremely complex behavior.  Given complex behavior, it is easy to see how one might begin to derive intelligence from the programs that have been described.  Not only is this complex behavior happening in the visual section, but there is dynamic behavior in the reasoning and auditory sections.  This means that the automaton could respond to things it hears in different ways.  

Now consider audible perception.  There are phenomena that can be explained by experimenting with the intelligence described in this paper.  Alison Gopnik has written about the “tower of babble” that appears in children at about 18 months (Gopnik, 1992).  This is when babies begin to “goo” and “dah” at everything.  An interesting finding that was reported by Gopnik is that the sounds that these children make are similar in their consonant and vowel construction, but different in their inflection.  The inflection used by early children is characteristic of the language that the child’s parents speak.  That is, a Chinese child will use much more inflection while babbling than an American child.  

If the memory network now captures sound as well, the computer becomes capable of grouping sounds and weighting them according to criteria that it learns about.  If the computer is then given the ability to generate “babble” based on the groupings that are found in the recorded audio, it is conceivable that the responses would sound similar to the language that the intelligence was being presented with.  With these associations in place, the intelligence can also begin to modify its behavior based on associations between different sounds.

With advances in speech recognition and other audio processing algorithms, computers are now able to understand humans and derive meaning from the things that they say.  Microsoft has recently unveiled a new technology that translates spoken English into spoken Chinese in the same voice (“BBC News”, 2012).  Though this technology doesn’t understand what the person is saying, clearly it is possible to discern words from speech in an efficient way.  Using natural language processing innovations that have been used by Watson and Siri, programs can also detect meaning in the words to a reasonable accuracy.



Hardware
---------

Humanity is nearing the end of Moore’s law.  Moore’s law states that the number of transistors on an integrated circuit in a given space will double every 18 months or so (Moore, 1965).  Unfortunately, this only works to a certain size.  Transistors can only be made so small - transistors are currently measured on atomic scales.  Fortunately, there is hope for humanity to sidestep the end of Moore’s law.  On October 28, 2011 Lockheed Martin installed a quantum computer (Knapp).  This quantum computer is oddly reminiscent of the mainframes that were around at the beginning of the age of electronic computers.  

“One of the first contributions that [quantum computer] offers to AI is the production of truly random numbers.  True randomness has been reported to cause measurable performance improvement to genetic programming and other automatic program induction methods” (Rylander et al., 2001).  Currently, there is a great deal of theoretical research pursuing algorithms in quantum computing.  “It is evident that many problems in search, planning, scheduling, game-playing, and other analogous fields can utilize the parallel processing of a quantum register’s contents and reduce their processing times by several orders of magnitude” (Sgarbas, 2007).  Quantum computing raises the possibility of solving AI problems that are too difficult for classical computing to do.  

Another problem that must be solved is that of storage.  The “network of memories” that was discussed previously takes up huge amounts of storage. “[T]he 100-trillion- synapse brain would hold the equivalent of 100 million megabytes” (Moravec, 1998).  100 million megabytes of memory is equivalent to approximately 100 terabytes.  While this number is large, it is certainly not unreasonable with current technology.  One could build a system with 100 TB of memory in a car with a significant amount of extra space.  This car could represent the automaton that was previously discussed.  However, if this seems a bit large, advancements in storage techniques could facilitate the building of smaller systems with the same amount of memory.  Once again, quantum physics comes to the rescue. 

There is research emerging around a technology called “quantum holography” which aims to significantly reduce the size of storage mechanisms.  “Holographic optical interconnect technology leads to a very high packing density, to a simplified connection complexity, and to reduced drive requirements.” (Schemp, 1992) Furthermore “the quantum holographic approach is also applicable to the Soffer optical resonator and the optical processing of synthetic aperture radar (SAR) data which represent particularly important examples of optical neurocomputer architectures.” (Schemp, 1992)

Even without all of the potential advances in computers, many of the algorithms that are used today can perform important artificial intelligence processes at remarkable speed.  A redeeming quality of genetic algorithms is that they are highly parallelizable.  This gives the artificial intelligence a huge performance boost.  The speech translator that Microsoft just unveiled is almost instantaneous.  That means that with the power of a computer that can be held in the palm of a hand, it is possible to break down incoming audio signal, classify it, perform translations, and modify the incoming audio to be spoken in the language of the output.  


---------

References
---------

Coello, Carlos A., Alan D. Christiansen, and Arturo Hernández Aguire. "Automated Design of Combinational Logic Circuits Using Genetic Algorithms." Artificial Intelligence for Engineering Design, Analysis and Manufacturing. 16.1 (2002): 39-53.

Gopnik, Alison, and Henry M. Wellman. "Why the child's theory of mind really is a theory." Mind & Language 7.1‐2 (1992): 145-171.

Knapp, Alex. "Lockheed Martin Installs Quantum Computer."Forbes. 31 Oct 2011: Web. 1 Dec. 2012. 

Kurzweil, Ray. The Singularity Is Near, When Humans Transcend Biology. Penguin Group USA, 2008.

"Microsoft demos instant English-Chinese translation." BBC News. 09 Nov 2012: Web. 1 Dec. 2012. <bbc.co.uk>.

Moravec, Hans. "When will computer hardware match the human brain."Journal of evolution and technology 1.1 (1998): 10.

Moore, Gordon E. "Cramming more components onto integrated circuits, Reprinted from Electronics, volume 38, number 8, April 19, 1965, pp. 114 ff."Solid-State Circuits Newsletter, IEEE 11.5 (2006): 33-35. Richter, Hendrik, and Shengxiang Yang. "Memory based on abstraction for dynamic fitness functions." Applications of Evolutionary Computing (2008): 596-605.

Rylander, B., Soule, T., Foster, J., Alves-Foss, J. (2001),  Quantum Evolutionary Programming, in Spector, L. et al. (eds.), Proc. of the Genetic and Evolutionary Computation Conference (GECCO-2001), San Francisco, USA, pp.1005-1011.

Schempp, Walter. "Quantum holography and neurocomputer architectures."Journal of Mathematical Imaging and Vision 2.4 (1992): 279-326.

Searle, John R. "Minds, brains, and programs." Behavioral and brain sciences3.3 (1980): 417-457

Sgarbas, Kyriakos N. "The road to quantum artificial intelligence." arXiv preprint arXiv:0705.3360 (2007). 

Turing, Alan M. "Computing Machinery and Intelligence."Mind. 59.236 (1950): 433-460.

